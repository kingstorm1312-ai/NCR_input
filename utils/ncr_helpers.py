import pandas as pd
from datetime import datetime, timedelta
import streamlit as st
import gspread
import cloudinary
import cloudinary.uploader
import io
import json

def get_now_vn():
    """L·∫•y th·ªùi gian hi·ªán t·∫°i theo m√∫i gi·ªù Vi·ªát Nam (GMT+7)"""
    return datetime.utcnow() + timedelta(hours=7)

def get_now_vn_str():
    """L·∫•y chu·ªói th·ªùi gian hi·ªán t·∫°i VN ƒë·ªãnh d·∫°ng chu·∫©n"""
    return get_now_vn().strftime("%Y-%m-%d %H:%M:%S")

@st.cache_resource
def init_gspread():
    """Kh·ªüi t·∫°o gspread client t·ª´ secrets (D√πng chung to√†n h·ªá th·ªëng)"""
    try:
        creds_str = st.secrets["connections"]["gsheets"]["service_account"]
        if isinstance(creds_str, str):
            creds_dict = json.loads(creds_str, strict=False)
        else:
            creds_dict = creds_str
        gc = gspread.service_account_from_dict(creds_dict)
        return gc
    except Exception as e:
        st.error(f"L·ªói kh·ªüi t·∫°o gspread: {e}")
        return None

# --- CONFIGURATION ---
LIST_DON_VI_TINH = ["C√°i", "Kg", "M√©t", "B·ªãch", "S·ª£i", "Cu·ªôn", "B·ªô"]

# --- STATUS FLOW CONFIGURATION ---
STATUS_FLOW = {
    'draft': 'cho_truong_ca',
    'cho_truong_ca': 'cho_truong_bp',
    'cho_truong_bp': 'cho_qc_manager',
    'cho_qc_manager': 'cho_giam_doc',
    'cho_giam_doc': 'cho_bgd_tan_phu',      # Director -> BGD Tan Phu
    'cho_bgd_tan_phu': 'hoan_thanh',        # Root -> Finish
    'hoan_thanh': 'hoan_thanh'
}

# Rejection escalation mapping
REJECT_ESCALATION = {
    'cho_truong_ca': 'draft',
    'cho_truong_bp': 'draft',
    'cho_qc_manager': 'draft',
    'cho_giam_doc': 'draft',
    'cho_bgd_tan_phu': 'draft'
}


# --- COLUMN MAPPING (Code ‚Üí Sheet) ---
# Map t√™n c·ªôt chu·∫©n trong code sang t√™n c·ªôt th·ª±c t·∫ø trong Google Sheet
COLUMN_MAPPING = {
    'so_phieu': 'so_phieu_ncr',
    'sl_loi': 'so_luong_loi',
    'nguon_goc': 'nguon_goc',
    'phan_loai': 'phan_loai',
    'hop_dong': 'hop_dong',
    'ma_vat_tu': 'ma_vat_tu',
    'ten_sp': 'ten_sp',
    'sl_kiem': 'so_luong_kiem',
    'md_loi': 'muc_do',
    'mo_ta_loi': 'mo_ta_loi',
    'sl_lo_hang': 'so_luong_lo_hang',
    'nguoi_lap_phieu': 'nguoi_lap_phieu',
    'noi_gay_loi': 'noi_gay_loi',
    'trang_thai': 'trang_thai',
    'thoi_gian_cap_nhat': 'thoi_gian_cap_nhat',
    'nguoi_duyet_1': 'duyet_truong_ca',
    'nguoi_duyet_2': 'duyet_truong_bp',
    'nguoi_duyet_3': 'duyet_qc_manager',
    'nguoi_duyet_4': 'duyet_giam_doc',
    'nguoi_duyet_5': 'duyet_bgd_tan_phu',
    'bien_phap_truong_bp': 'bien_phap_truong_bp',
    'huong_giai_quyet': 'y_kien_qc',
    'huong_xu_ly_gd': 'huong_xu_ly_giam_doc',
    'ly_do_tu_choi': 'ly_do_tu_choi',
    'hinh_anh': 'hinh_anh',
    'don_vi_tinh': 'don_vi_tinh',
    # H√†nh ƒë·ªông kh·∫Øc ph·ª•c (Corrective Action)
    'kp_status': 'kp_status',
    'kp_assigned_by': 'kp_assigned_by',
    'kp_assigned_to': 'kp_assigned_to',
    'kp_message': 'kp_message',
    'kp_deadline': 'kp_deadline',
    'kp_response': 'kp_response',
    'so_lan': 'so_lan'
}

ROLE_TO_APPROVER_COLUMN = {
    'truong_ca': 'nguoi_duyet_1',
    'truong_bp': 'nguoi_duyet_2',
    'qc_manager': 'nguoi_duyet_3',
    'director': 'nguoi_duyet_4',
    'bgd_tan_phu': 'nguoi_duyet_5'
}

ROLE_TO_STATUS = {
    'truong_ca': 'cho_truong_ca',
    'truong_bp': 'cho_truong_bp',
    'qc_manager': 'cho_qc_manager',
    'director': 'cho_giam_doc',
    'bgd_tan_phu': 'cho_bgd_tan_phu'
}

# --- CACHED DATA FETCH ---
@st.cache_data(ttl=30, show_spinner=False)
def _get_ncr_data_cached():
    try:
        gc = init_gspread()
        if not gc: return pd.DataFrame()
        
        spreadsheet_id = st.secrets["connections"]["gsheets"]["spreadsheet"]
        sh = gc.open_by_key(spreadsheet_id)
        ws = sh.worksheet("NCR_DATA")
        records = ws.get_all_records()
        df = pd.DataFrame(records)
        return df
    except Exception as e:
        # st.error(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        return pd.DataFrame()


# --- DATA LOADING & GROUPING ---
def load_ncr_data_with_grouping(gc=None, filter_status=None, filter_department=None):
    try:
        df_original = _get_ncr_data_cached()
        
        if df_original.empty:
            st.warning("üìä Sheet NCR_DATA tr·ªëng. Ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã.")
            return pd.DataFrame(), pd.DataFrame()
        
        # Normalize column names
        df_original.columns = df_original.columns.str.strip()
        
        # Create reverse mapping
        reverse_mapping = {v: k for k, v in COLUMN_MAPPING.items()}
        df_original = df_original.rename(columns=reverse_mapping)
        
        # Apply filters
        df_filtered = df_original.copy()
        
        if filter_status:
            if 'trang_thai' in df_filtered.columns:
                if isinstance(filter_status, list):
                    df_filtered = df_filtered[df_filtered['trang_thai'].astype(str).str.strip().isin(filter_status)]
                else:
                    df_filtered = df_filtered[df_filtered['trang_thai'].astype(str).str.strip() == filter_status]
        
        if filter_department:
            if 'so_phieu' in df_filtered.columns:
                def extract_dept(so_phieu):
                    parts = str(so_phieu).split('-')
                    if len(parts) >= 2:
                        return '-'.join(parts[:2]).lower().replace('-', '_')
                    elif len(parts) == 1:
                        return parts[0].lower()
                    return ''
                
                df_filtered['bo_phan'] = df_filtered['so_phieu'].apply(extract_dept)
                
                # Normalize filter_department for comparison
                filter_dept_norm = str(filter_department).lower().strip()
                
                # Condition 1: Origin Department (Standard)
                condition_origin = df_filtered['bo_phan'] == filter_dept_norm
                
                # Condition 2: Cross-Department Assignment
                # Logic: Status starts with 'khac_phuc_' AND kp_message contains [BP: Department]
                condition_cross = pd.Series([False] * len(df_filtered), index=df_filtered.index)
                
                if 'kp_message' in df_filtered.columns and 'trang_thai' in df_filtered.columns:
                    tag = f"[bp: {filter_dept_norm}]"
                    
                    msgs = df_filtered['kp_message'].fillna('').astype(str).str.lower()
                    statuses = df_filtered['trang_thai'].fillna('').astype(str).str.lower()
                    
                    is_khac_phuc = statuses.str.startswith('khac_phuc_')
                    has_tag = msgs.str.contains(tag, regex=False)
                    
                    condition_cross = is_khac_phuc & has_tag
                
                # Combine Filters
                df_filtered = df_filtered[condition_origin | condition_cross]
        
        if df_filtered.empty:
            return df_original, pd.DataFrame()
        
        # Grouping
        group_cols = {
            'ngay_lap': 'first',
            'nguoi_lap_phieu': 'first',
            'trang_thai': 'first',
            'sl_loi': 'sum',
            'ten_loi': lambda x: ', '.join(sorted(set(x.astype(str))))
        }
        
        # Add optional columns if they exist
        optional_cols = [
            'hop_dong', 'ma_vat_tu', 'ten_sp', 'phan_loai', 'nguon_goc', 
            'sl_kiem', 'mo_ta_loi', 'sl_lo_hang', 'hinh_anh',
            'thoi_gian_cap_nhat', 'nguoi_duyet_1', 'nguoi_duyet_2', 
            'nguoi_duyet_3', 'nguoi_duyet_4', 'nguoi_duyet_5', 
            'bien_phap_truong_bp', 'huong_giai_quyet', 'huong_xu_ly_gd', 'ly_do_tu_choi',
            'kp_status', 'kp_assigned_by', 'kp_assigned_to', 'kp_message', 'kp_deadline', 'kp_response',
            'don_vi_tinh'
        ]
        
        for col in optional_cols:
            if col in df_filtered.columns:
                group_cols[col] = 'first'
        
        # Robust groupby
        if 'so_phieu' in df_filtered.columns:
            grouped = df_filtered.groupby('so_phieu', as_index=False).agg(group_cols)
            return df_original, grouped
        else:
             return df_original, pd.DataFrame()

    except Exception as e:
        st.error(f"L·ªói x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
        return pd.DataFrame(), pd.DataFrame()


# Prefix Mapping
DEPT_PREFIX_MAP = {
    "FI": ("FI", "FI"),
    "NPLDV": ("ƒêV Cu·ªôn", "ƒêV Cu·ªôn"),
    "DVNPL": ("ƒêV NPL", "ƒêV NPL"),
    "X2-TR": ("Tr√°ng C·∫Øt", "Tr√°ng"),
    "X2-CA": ("Tr√°ng C·∫Øt", "C·∫Øt"),
    "I'": ("May", "May I"),
    "XA": ("May", "May P2"),
    "X4": ("May", "May N4"),
    "X3": ("May", "May A2"),
    "DVTP": ("TP ƒê·∫ßu V√†o", "TP ƒê·∫ßu V√†o"),
    "XG-IN": ("In X∆∞·ªüng D", "In"),
    "XG-SA": ("In X∆∞·ªüng D", "Si√™u √Çm"),
    "CAT-BAN": ("C·∫Øt", "C·∫Øt B√†n"),
    "XT": ("Xeo T·ª∑", "Xeo T·ª∑"), # D·ª± tr√π n·∫øu c√≥
    "CAT_BAN": ("C·∫Øt", "C·∫Øt B√†n"),
}

@st.cache_data(ttl=300)
def load_ncr_dataframe_v2():
    try:
        gc = init_gspread()
        if not gc: return pd.DataFrame()
        
        sh = gc.open_by_key(st.secrets["connections"]["gsheets"]["spreadsheet"])
        ws = sh.worksheet("NCR_DATA")
        records = ws.get_all_records()
        df = pd.DataFrame(records)
        
        if df.empty:
            return pd.DataFrame()
        
        df.columns = df.columns.str.strip()
        inv_map = {v: k for k, v in COLUMN_MAPPING.items()}
        df.rename(columns=inv_map, inplace=True)
        
        if 'ngay_lap' in df.columns:
            df['date_obj'] = pd.to_datetime(df['ngay_lap'], dayfirst=True, errors='coerce')
            df['year'] = df['date_obj'].dt.year
            df['month'] = df['date_obj'].dt.month
            df['week'] = df['date_obj'].dt.isocalendar().week
        
        # Ensure hop_dong column exists (it should already be mapped from COLUMN_MAPPING)
        if 'hop_dong' not in df.columns and 'so_hop_dong' in df.columns:
            df['hop_dong'] = df['so_hop_dong']
        
        if 'so_phieu' in df.columns:
            def extract_dept_info(so_phieu):
                s = str(so_phieu).upper().strip()
                sorted_prefixes = sorted(DEPT_PREFIX_MAP.keys(), key=len, reverse=True)
                for prefix in sorted_prefixes:
                    if s.startswith(prefix):
                        bp, khau = DEPT_PREFIX_MAP[prefix]
                        return pd.Series([bp, khau])
                parts = s.split('-')
                val = parts[0]
                return pd.Series([val, val])

            df[['bo_phan', 'bo_phan_full']] = df['so_phieu'].apply(extract_dept_info)

        if 'thoi_gian_cap_nhat' in df.columns:
            df['hours_stuck'] = df['thoi_gian_cap_nhat'].apply(calculate_stuck_time)
        else:
            df['hours_stuck'] = 0
            
        return df
        
    except Exception as e:
        st.error(f"L·ªói load data chung: {e}")
        return pd.DataFrame()


# --- HELPER FUNCTIONS ---
def get_status_display_name(status):
    if isinstance(status, list):
        return " / ".join([get_status_display_name(s) for s in status])
    status = str(status).strip()
    names = {
        'draft': 'Nh√°p (C·∫ßn x·ª≠ l√Ω)',
        'cho_truong_ca': 'Ch·ªù Tr∆∞·ªüng ca',
        'cho_truong_bp': 'Ch·ªù Tr∆∞·ªüng BP',
        'cho_qc_manager': 'Ch·ªù QC Manager',
        'cho_giam_doc': 'Ch·ªù Gi√°m ƒë·ªëc',
        'cho_bgd_tan_phu': 'Ch·ªù BGƒê T√¢n Ph√∫',
        'hoan_thanh': 'Ho√†n th√†nh'
    }
    # Dynamic handling for corrective action confirm
    if status.startswith("xac_nhan_kp_"):
         role_suffix = status.replace("xac_nhan_kp_", "")
         return f"X√°c nh·∫≠n Kh·∫Øc ph·ª•c ({role_suffix.upper()})"
         
    if 'tu_choi' in status:
        return f"B·ªã t·ª´ ch·ªëi ({status})"
    return names.get(status, status)


def get_status_color(status):
    status = str(status).strip()
    colors = {
        'draft': 'gray',
        'cho_truong_ca': 'blue',
        'cho_truong_bp': 'orange',
        'cho_qc_manager': 'violet',
        'cho_giam_doc': 'red',
        'cho_bgd_tan_phu': 'red',
        'hoan_thanh': 'green'
    }
    if 'tu_choi' in status:
        return 'red'
    return colors.get(status, 'gray')


def format_contract_code(raw_input):
    if not raw_input:
        return ""
    s = str(raw_input).strip()
    import re
    match = re.search(r'^(\d+)[\W_]+(\d+)\s*([a-zA-Z]*)$', s)
    if match:
        p1, p2, suffix = match.groups()
        suffix_upper = suffix.upper() if suffix else ""
        return f"{p1}/{p2}{suffix_upper}"
    s = re.sub(r'[\s\.\-,]+', '/', s)
    return s.upper()


def render_input_buffer_mobile(buffer_list):
    if not buffer_list:
        return buffer_list

    st.markdown("##### üõí Danh s√°ch l·ªói ƒë√£ th√™m:")
    indices_to_remove = []
    
    for i, err in enumerate(buffer_list):
        with st.container(border=True):
            c1, c2 = st.columns([5, 1])
            with c1:
                st.markdown(f"**{i+1}. {err['ten_loi']}**")
                muc_do = err.get('muc_do', '')
                dvt = err.get('don_vi_tinh', '')
                st.caption(f"SL: **{err['sl_loi']} {dvt}** | V·ªã tr√≠: {err.get('vi_tri', '')} | M·ª©c ƒë·ªô: {muc_do}")
            with c2:
                if st.button("üóëÔ∏è", key=f"del_buf_{err['ten_loi']}_{i}", help="X√≥a"):
                    indices_to_remove.append(i)

    if indices_to_remove:
        for index in sorted(indices_to_remove, reverse=True):
            buffer_list.pop(index)
        st.rerun()
    
    return buffer_list


def calculate_stuck_time(last_update_str):
    if not last_update_str:
        return 0
    try:
        last_update = pd.to_datetime(str(last_update_str), dayfirst=True)
        if pd.isna(last_update):
            return 0
        delta = get_now_vn() - last_update
        return delta.total_seconds() / 3600
    except:
        return 0

# --- CLOUDINARY UPLOAD ---
def upload_images_to_cloud(file_list, filename_prefix):
    """
    Upload images to Cloudinary.
    Requires [cloudinary] section in secrets.toml with cloud_name, api_key, api_secret.
    """
    if not file_list:
        return ""
    
    try:
        # Initialize Config
        cld = st.secrets["cloudinary"]
        cloudinary.config(
            cloud_name=cld["cloud_name"],
            api_key=cld["api_key"],
            api_secret=cld["api_secret"],
            secure=True
        )
        
        urls = []
        for idx, uploaded_file in enumerate(file_list):
            try:
                # Cloudinary uploader accepts file-like objects (BytesIO) directly
                # folder='ncr_images' keeps things organized
                # public_id ensure uniqueness
                timestamp = int(get_now_vn().timestamp())
                res = cloudinary.uploader.upload(
                    uploaded_file, 
                    folder="ncr_images",
                    public_id=f"{filename_prefix}_{timestamp}_{idx}",
                    resource_type="image"
                )
                urls.append(res.get("secure_url"))
            except Exception as e:
                st.error(f"L·ªói upload ·∫£nh {uploaded_file.name}: {e}")
                
        return "\n".join(urls)
        
    except Exception as e:
        st.error(f"L·ªói c·∫•u h√¨nh Cloudinary: {e}")
        return ""


def smart_append_ncr(ws, data_dict):
    """
    Appends a row to Google Sheets based on headers.
    Matches keys in data_dict with headers in row 1 of ws (case-insensitive).
    """
    try:
        # 1. L·∫•y headers t·ª´ row 1
        headers = ws.row_values(1)
        
        # 2. Chu·∫©n h√≥a data_dict (strip v√† lowercase keys)
        normalized_data = {str(k).strip().lower(): v for k, v in data_dict.items()}
        
        # 3. X√¢y d·ª±ng row list d·ª±a tr√™n header
        # Map d·ªØ li·ªáu theo t√™n c·ªôt (chu·∫©n h√≥a header ƒë·ªÉ t√¨m trong normalized_data)
        row_to_append = []
        for h in headers:
            normalized_h = str(h).strip().lower()
            val = normalized_data.get(normalized_h, "")
            row_to_append.append(val)
        
        # 4. Append v√†o sheet
        if any(row_to_append): # Ch·ªâ l∆∞u n·∫øu c√≥ √≠t nh·∫•t m·ªôt gi√° tr·ªã (tr√°nh d√≤ng tr·ªëng)
            ws.append_row(row_to_append)
            return True
        else:
            st.error("‚ö†Ô∏è D·ªØ li·ªáu kh√¥ng kh·ªõp v·ªõi b·∫•t k·ª≥ c·ªôt n√†o tr√™n Sheet. Vui l√≤ng ki·ªÉm tra l·∫°i Header!")
            return False
            
    except Exception as e:
        st.error(f"L·ªói khi l∆∞u d√≤ng d·ªØ li·ªáu: {e}")
        return False


def update_ncr_status(gc, so_phieu, new_status, approver_name, approver_role, solution=None, reject_reason=None, bp_solution=None, director_solution=None, assignee=None):
    """
    C·∫≠p nh·∫≠t tr·∫°ng th√°i v√† th√¥ng tin ph√™ duy·ªát cho t·∫•t c·∫£ c√°c d√≤ng c·ªßa m·ªôt s·ªë phi·∫øu.
    
    Args:
        solution: H∆∞·ªõng gi·∫£i quy·∫øt c·ªßa QC Manager (y_kien_qc)
        bp_solution: Bi·ªán ph√°p x·ª≠ l√Ω t·ª©c th·ªùi c·ªßa Tr∆∞·ªüng BP (bien_phap_truong_bp)
        director_solution: H∆∞·ªõng x·ª≠ l√Ω c·ªßa Gi√°m ƒë·ªëc (huong_xu_ly_giam_doc)
        assignee: T√™n ng∆∞·ªùi ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh (n·∫øu c√≥), d√πng cho vi·ªác Director c·ª• th·ªÉ
    """
    try:
        sh = gc.open_by_key(st.secrets["connections"]["gsheets"]["spreadsheet"])
        ws = sh.worksheet("NCR_DATA")
        data = ws.get_all_values()
        headers = [str(h).strip().lower() for h in data[0]]
        
        # T√¨m ch·ªâ m·ª•c c√°c c·ªôt c·∫ßn thi·∫øt (Case-insensitive)
        idx_so_phieu = headers.index("so_phieu_ncr")
        idx_status = headers.index("trang_thai")
        idx_update = headers.index("thoi_gian_cap_nhat")
        
        idx_reject = headers.index("ly_do_tu_choi") if "ly_do_tu_choi" in headers else -1
        idx_qc_solution = headers.index("y_kien_qc") if "y_kien_qc" in headers else -1
        idx_bp_solution = headers.index("bien_phap_truong_bp") if "bien_phap_truong_bp" in headers else -1
        idx_director_solution = headers.index("huong_xu_ly_giam_doc") if "huong_xu_ly_giam_doc" in headers else -1
        
        # C·ªôt ng∆∞·ªùi duy·ªát d·ª±a tr√™n vai tr√≤
        approver_col_name = COLUMN_MAPPING.get(ROLE_TO_APPROVER_COLUMN.get(approver_role), "")
        idx_approver = headers.index(approver_col_name.lower()) if approver_col_name.lower() in headers else -1
        
        now = get_now_vn_str()
        range_updates = []
        
        for i, row in enumerate(data[1:], start=2):
            if str(row[idx_so_phieu]).strip() == str(so_phieu).strip():
                # Tr·∫°ng th√°i & Th·ªùi gian
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_status + 1), 'values': [[new_status]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_update + 1), 'values': [[now]]})
                
                # T√™n ng∆∞·ªùi duy·ªát
                if idx_approver != -1:
                    range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_approver + 1), 'values': [[approver_name]]})
                
                # Bi·ªán ph√°p c·ªßa Tr∆∞·ªüng BP
                if bp_solution and idx_bp_solution != -1:
                    range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_bp_solution + 1), 'values': [[bp_solution]]})
                
                # H∆∞·ªõng gi·∫£i quy·∫øt c·ªßa QC Manager
                if solution and idx_qc_solution != -1:
                    full_solution = solution
                    if assignee:
                        full_solution = f"{full_solution}\n[Ch·ªâ ƒë·ªãnh: {assignee}]"
                    range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_qc_solution + 1), 'values': [[full_solution]]})
                
                # H∆∞·ªõng x·ª≠ l√Ω c·ªßa Gi√°m ƒë·ªëc
                if director_solution and idx_director_solution != -1:
                    range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_director_solution + 1), 'values': [[director_solution]]})
                
                # L√Ω do t·ª´ ch·ªëi (N·∫øu c√≥)
                if reject_reason and idx_reject != -1:
                    full_reject = f"[{approver_name} ({approver_role.upper()})] {reject_reason}"
                    range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_reject + 1), 'values': [[full_reject]]})
        
        if range_updates:
            ws.batch_update(range_updates)
            return True, "C·∫≠p nh·∫≠t tr·∫°ng th√°i th√†nh c√¥ng"
        return False, "Kh√¥ng t√¨m th·∫•y s·ªë phi·∫øu NCR n√†y"
        
    except Exception as e:
        return False, f"L·ªói h·ªá th·ªëng: {e}"


def restart_ncr(gc, so_phieu, target_status, user_name, note=""):
    """
    Kh√¥i ph·ª•c/Restart m·ªôt phi·∫øu NCR v·ªÅ tr·∫°ng th√°i ch·ªâ ƒë·ªãnh.
    D√πng trong trang Gi√°m s√°t.
    """
    try:
        sh = gc.open_by_key(st.secrets["connections"]["gsheets"]["spreadsheet"])
        ws = sh.worksheet("NCR_DATA")
        data = ws.get_all_values()
        headers = [str(h).strip().lower() for h in data[0]]
        
        idx_so_phieu = headers.index("so_phieu_ncr")
        idx_status = headers.index("trang_thai")
        idx_update = headers.index("thoi_gian_cap_nhat")
        idx_reject = headers.index("ly_do_tu_choi") if "ly_do_tu_choi" in headers else -1
        
        now = get_now_vn_str()
        range_updates = []
        
        for i, row in enumerate(data[1:], start=2):
            if str(row[idx_so_phieu]).strip() == str(so_phieu).strip():
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_status + 1), 'values': [[target_status]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_update + 1), 'values': [[now]]})
                
                if idx_reject != -1:
                    msg = f"[RESTART BY {user_name}] {note}"
                    range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_reject + 1), 'values': [[msg]]})
        
        if range_updates:
            ws.batch_update(range_updates)
            return True, f"ƒê√£ kh√¥i ph·ª•c phi·∫øu {so_phieu} v·ªÅ {target_status}"
        return False, "Kh√¥ng t√¨m th·∫•y phi·∫øu"
    except Exception as e:
        return False, f"L·ªói: {str(e)}"
def assign_corrective_action(gc, so_phieu, assigned_by_role, assign_to_role, message, deadline, target_department=None, target_person=None):
    """
    Giao h√†nh ƒë·ªông kh·∫Øc ph·ª•c cho c·∫•p d∆∞·ªõi.
    """
    try:
        sh = gc.open_by_key(st.secrets["connections"]["gsheets"]["spreadsheet"])
        ws = sh.worksheet("NCR_DATA")
        data = ws.get_all_values()
        headers = [str(h).strip().lower() for h in data[0]]
        
        idx_so_phieu = headers.index("so_phieu_ncr")
        idx_status = headers.index("trang_thai")
        idx_update = headers.index("thoi_gian_cap_nhat")
        
        idx_kp_status = headers.index("kp_status")
        idx_kp_by = headers.index("kp_assigned_by")
        idx_kp_to = headers.index("kp_assigned_to")
        idx_kp_msg = headers.index("kp_message")
        idx_kp_dl = headers.index("kp_deadline")
        idx_kp_res = headers.index("kp_response")
        
        # X√°c ƒë·ªãnh tr·∫°ng th√°i m·ªõi
        new_status = f"khac_phuc_{assign_to_role}"
        now = get_now_vn_str()
        range_updates = []
        
        for i, row in enumerate(data[1:], start=2):
            if str(row[idx_so_phieu]).strip() == str(so_phieu).strip():
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_status + 1), 'values': [[new_status]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_update + 1), 'values': [[now]]})
                
                final_message = message
                prefix_info = []
                if target_department:
                    prefix_info.append(f"BP: {target_department}")
                if target_person:
                     prefix_info.append(f"Ch·ªâ ƒë·ªãnh: {target_person}")
                
                if prefix_info:
                    final_message = f"[{' | '.join(prefix_info)}] {final_message}"

                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_status + 1), 'values': [['active']]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_by + 1), 'values': [[assigned_by_role]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_to + 1), 'values': [[assign_to_role]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_msg + 1), 'values': [[final_message]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_dl + 1), 'values': [[str(deadline)]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_res + 1), 'values': [['']]}) # Reset response
        
        if range_updates:
            ws.batch_update(range_updates)
            return True, f"ƒê√£ giao h√†nh ƒë·ªông kh·∫Øc ph·ª•c cho {assign_to_role.upper()}"
        return False, "Kh√¥ng t√¨m th·∫•y s·ªë phi·∫øu"
    except Exception as e:
        return False, f"L·ªói h·ªá th·ªëng: {e}"

def complete_corrective_action(gc, so_phieu, response):
    """
    Ng∆∞·ªùi nh·∫≠n ho√†n th√†nh h√†nh ƒë·ªông kh·∫Øc ph·ª•c v√† g·ª≠i l·∫°i cho ng∆∞·ªùi giao.
    """
    try:
        sh = gc.open_by_key(st.secrets["connections"]["gsheets"]["spreadsheet"])
        ws = sh.worksheet("NCR_DATA")
        data = ws.get_all_values()
        headers = [str(h).strip().lower() for h in data[0]]
        
        idx_so_phieu = headers.index("so_phieu_ncr")
        idx_status = headers.index("trang_thai")
        idx_update = headers.index("thoi_gian_cap_nhat")
        idx_kp_status = headers.index("kp_status")
        idx_kp_by = headers.index("kp_assigned_by")
        idx_kp_res = headers.index("kp_response")
        
        now = get_now_vn_str()
        range_updates = []
        
        # L·∫•y th√¥ng tin ng∆∞·ªùi giao t·ª´ d√≤ng ƒë·∫ßu ti√™n t√¨m th·∫•y
        assigned_by = ""
        for row in data[1:]:
            if str(row[idx_so_phieu]).strip() == str(so_phieu).strip():
                assigned_by = str(row[idx_kp_by]).strip()
                break
        
        if not assigned_by:
            return False, "Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c ng∆∞·ªùi giao task"
            
        # Tr·∫°ng th√°i ch·ªù x√°c nh·∫≠n
        new_status = f"xac_nhan_kp_{assigned_by}"
        
        for i, row in enumerate(data[1:], start=2):
            if str(row[idx_so_phieu]).strip() == str(so_phieu).strip():
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_status + 1), 'values': [[new_status]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_update + 1), 'values': [[now]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_status + 1), 'values': [['completed']]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_res + 1), 'values': [[response]]})
        
        if range_updates:
            ws.batch_update(range_updates)
            return True, f"ƒê√£ g·ª≠i ph·∫£n h·ªìi kh·∫Øc ph·ª•c cho {assigned_by.upper()}"
        return False, "Kh√¥ng t√¨m th·∫•y s·ªë phi·∫øu"
    except Exception as e:
        return False, f"L·ªói h·ªá th·ªëng: {e}"

def accept_corrective_action(gc, so_phieu, approver_role):
    """
    Ng∆∞·ªùi giao ch·∫•p nh·∫≠n h√†nh ƒë·ªông kh·∫Øc ph·ª•c, phi·∫øu quay l·∫°i tr·∫°ng th√°i ch·ªù duy·ªát c·ªßa h·ªç.
    """
    try:
        sh = gc.open_by_key(st.secrets["connections"]["gsheets"]["spreadsheet"])
        ws = sh.worksheet("NCR_DATA")
        data = ws.get_all_values()
        headers = [str(h).strip().lower() for h in data[0]]
        
        idx_so_phieu = headers.index("so_phieu_ncr")
        idx_status = headers.index("trang_thai")
        idx_update = headers.index("thoi_gian_cap_nhat")
        idx_kp_status = headers.index("kp_status")
        
        # Quay l·∫°i tr·∫°ng th√°i ch·ªù duy·ªát c·ªßa ch√≠nh role ƒë√≥
        new_status = ROLE_TO_STATUS.get(approver_role)
        now = get_now_vn_str()
        range_updates = []
        
        for i, row in enumerate(data[1:], start=2):
            if str(row[idx_so_phieu]).strip() == str(so_phieu).strip():
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_status + 1), 'values': [[new_status]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_update + 1), 'values': [[now]]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_kp_status + 1), 'values': [['accepted']]})
        
        if range_updates:
            ws.batch_update(range_updates)
            return True, "ƒê√£ ch·∫•p nh·∫≠n h√†nh ƒë·ªông kh·∫Øc ph·ª•c. Phi·∫øu ƒë√£ quay l·∫°i danh s√°ch ch·ªù duy·ªát."
        return False, "Kh√¥ng t√¨m th·∫•y s·ªë phi·∫øu"
    except Exception as e:
        return False, f"L·ªói h·ªá th·ªëng: {e}"

def load_pending_corrective_actions(gc, role_name):
    """
    Loads tickets that are in 'khac_phuc_truong_bp' status AND were assigned by the current role.
    """
    try:
        if not gc: return pd.DataFrame()
        
        # Load all data (cached)
        df = load_ncr_dataframe_v2()
        if df.empty: return pd.DataFrame()
        
        # Check if necessary columns exist
        required_cols = ['trang_thai', 'kp_assigned_by', 'so_phieu', 'kp_deadline', 'kp_assigned_to']
        for col in required_cols:
            if col not in df.columns:
                return pd.DataFrame() # Missing columns
        
        # Normalizing
        df['status_norm'] = df['trang_thai'].astype(str).str.strip().str.lower()
        df['by_norm'] = df['kp_assigned_by'].astype(str).str.strip().str.lower()
        
        # Filter Logic
        if role_name == 'all':
            mask_owner = pd.Series([True] * len(df)) # Select All
        else:
            role_norm = role_name.lower()
            mask_owner = df['by_norm'] == role_norm
        
        mask_status = df['status_norm'] == 'khac_phuc_truong_bp'
        
        df_pending = df[mask_status & mask_owner].copy()
        
        if df_pending.empty:
            return pd.DataFrame()
            
        # Group by Ticket
        group_cols = {
            'ngay_lap': 'first',
            'kp_assigned_to': 'first',
            'kp_deadline': 'first',
            'kp_message': 'first',
            'kp_assigned_by': 'first',
            'bo_phan': 'first',
            'sl_loi': 'sum'
        }
        # Add dynamic cols if exist
        for c in ['hop_dong', 'ten_sp']:
            if c in df_pending.columns:
                group_cols[c] = 'first'
                
        df_grouped = df_pending.groupby('so_phieu', as_index=False).agg(group_cols)
        
        return df_grouped
        
    except Exception as e:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def get_all_users():
    """L·∫•y danh s√°ch to√†n b·ªô nh√¢n vi√™n t·ª´ sheet USERS"""
    try:
        gc = init_gspread()
        if not gc: return []
        spreadsheet_id = st.secrets["connections"]["gsheets"]["spreadsheet"]
        sh = gc.open_by_key(spreadsheet_id)
        ws = sh.worksheet("USERS")
        data = ws.get_all_records()
        return data
    except Exception as e:
        return []

def cancel_ncr(gc, so_phieu, reason):
    """
    H·ªßy phi·∫øu NCR: Chuy·ªÉn tr·∫°ng th√°i sang 'da_huy'
    """
    try:
        sh = gc.open_by_key(st.secrets["connections"]["gsheets"]["spreadsheet"])
        ws = sh.worksheet("NCR_DATA")
        data = ws.get_all_values()
        headers = [str(h).strip().lower() for h in data[0]]
        
        idx_so_phieu = headers.index("so_phieu_ncr")
        idx_status = headers.index("trang_thai")
        idx_update = headers.index("thoi_gian_cap_nhat")
        idx_note = headers.index("ly_do_tu_choi") # Use this col for cancel reason
        
        now = get_now_vn_str()
        range_updates = []
        
        for i, row in enumerate(data[1:], start=2):
            if str(row[idx_so_phieu]).strip() == str(so_phieu).strip():
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_status + 1), 'values': [['da_huy']]})
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_update + 1), 'values': [[now]]})
                current_note = row[idx_note]
                new_note = f"{current_note} | [L√Ω do h·ªßy: {reason}]" if current_note else f"[L√Ω do h·ªßy: {reason}]"
                range_updates.append({'range': gspread.utils.rowcol_to_a1(i, idx_note + 1), 'values': [[new_note]]})
        
        if range_updates:
            ws.batch_update(range_updates)
            return True, f"ƒê√£ h·ªßy phi·∫øu {so_phieu}"
        return False, "Kh√¥ng t√¨m th·∫•y s·ªë phi·∫øu"
    except Exception as e:
        return False, f"L·ªói h·ªá th·ªëng: {e}"
